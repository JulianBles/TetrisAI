NIEUWE AANPAK:

Gebruik deep learning en neural networks om tetris te laten spelen.

Convolutional neural network is waarschijnlijk niet handig omdat elk detail moet worden gepakt.

Waarschijnlijk gwn puur linear layers met mogelijk activation functions. Aantal linear layers moet mee worden geklooid.

Mogelijk Rainbow DQN gebruiken of ander model dat goed met reinforcement learning werkt.



REINFORCMENT LEARNING DESIGN:

Observation space:
- 200 features, één voor elke pixel en dan kan alleen maar 0 of 1 zijn.
- Optie is om het aantal features te halveren en dat elke feature 4 opties heeft maar dat is uitproberen.

Action space:
- Hetzelfde als een normale speler (left, right, rotate, rotate-clockwise, down, drop)
- Elke rotation + positie als actie nemen (dat is 4 * 10 dus 40 acties is best veel en duurt lang om te leren)

Reward system:
- Als er 40 acties zijn is het maken van de reward system best makkelijk maar duurt waarschijnlijk erg lang om een goed model te trainen
- De betere optie bij normal player actions:
    -1 bij elke onnodige move (om sneller te droppen)
    +X voor droppen van piece op een plek zonder holes te creeren
    -Y voor droppen van piece op een plek waar holes worden gecreerd
    +Z voor lines clearen, 1,2,3 lines mag linear zijn maar 4 lines moet veel groter zijn

X, Y en Z moeten stuk groter zijn dan 1



Behulpzame linkjes:
- https://wiki.pathmind.com/deep-reinforcement-learning#:~:text=Deep%20reinforcement%20learning%20combines%20artificial,the%20rewards%20they%20lead%20to.
- https://en.wikipedia.org/wiki/Deep_reinforcement_learning
- https://paperswithcode.com/method/rainbow-dqn
    - Paper: https://arxiv.org/pdf/1710.02298.pdf
    - Code: https://github.com/thu-ml/tianshou
    - Helping guide: https://tianshou.readthedocs.io/en/master/tutorials/dqn.html
    - How to create your own gym.env: https://www.gymlibrary.dev/content/environment_creation/
    - Cheatsheet: https://tianshou.readthedocs.io/en/v0.4.0/tutorials/cheatsheet.html